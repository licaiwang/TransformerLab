{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "piano-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "scientific-budapest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dangerous-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=\"ERROR\")\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unexpected-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"nmt\"\n",
    "en_vocab_file = os.path.join(output_dir, \"en_vocab\")\n",
    "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\")\n",
    "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
    "log_dir = os.path.join(output_dir, 'logs')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-treaty",
   "metadata": {},
   "source": [
    "* 新聞評論：newscommentary_v14\n",
    "* 維基百科標題：wikititles_v1\n",
    "* 聯合國數據：uncorpus_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "drawn-patch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Split('train'): ['newscommentary_v14',\n",
       "  'wikititles_v1',\n",
       "  'uncorpus_v1',\n",
       "  'casia2015',\n",
       "  'casict2011',\n",
       "  'casict2015',\n",
       "  'datum2015',\n",
       "  'datum2017',\n",
       "  'neu2017'],\n",
       " Split('validation'): ['newstest2018']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_builder = tfds.builder(\"wmt19_translate/zh-en\")\n",
    "tmp_builder.subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thorough-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tfds.translate.wmt.WmtConfig(\n",
    "  version = tfds.core.Version('0.0.3', experiments={tfds.core.ReadInstruction: False}),\n",
    "  language_pair = (\"zh\", \"en\"),\n",
    "  subsets = {\n",
    "    tfds.Split.TRAIN: [\"newscommentary_v14\"],\n",
    "    tfds.Split.VALIDATION: [\"newstest2018\"],\n",
    "  }\n",
    ")\n",
    "builder = tfds.builder(\"wmt_translate\", config = config)\n",
    "builder.download_and_prepare()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accomplished-fitness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>,\n",
       " 'validation': <PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = builder.as_dataset(as_supervised=True)\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superb-corpus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((), ()), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = examples[\"train\"].take(300000)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medium-pierre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((), ()), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = examples[\"train\"].skip(300000).take(11556)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "delayed-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data = examples[\"validation\"]\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "material-anaheim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "underlying-aspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "skilled-interview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3981"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "superior-massage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'The fear is real and visceral, and politicians ignore it at their peril.', shape=(), dtype=string)\n",
      "tf.Tensor(b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82', shape=(), dtype=string)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for en, zh in train_data.take(1):\n",
    "    print(en)\n",
    "    print(zh)\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "utility-commission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fear is real and visceral, and politicians ignore it at their peril.\n",
      "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for en_t, zh_t in train_data.take(1):\n",
    "    en = en_t.numpy().decode(\"utf-8\")\n",
    "    zh = zh_t.numpy().decode(\"utf-8\")\n",
    "    print(en)\n",
    "    print(zh)\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-extreme",
   "metadata": {},
   "source": [
    "## 建立中文與英文字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "split-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dict(data,path,lang):\n",
    "    try:\n",
    "        subword_encoder = tfds.deprecated.text.SubwordTextEncoder.load_from_file(path)\n",
    "        print(f\"載入已建立的字典： {path}\")\n",
    "    except:\n",
    "        print(\"沒有已建立的字典，從頭建立。\")\n",
    "        if lang == \"en\":\n",
    "            print(\"Build English Dict\")\n",
    "            subword_encoder = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "          (w.numpy().decode(\"utf-8\") for w, _ in data), \n",
    "          target_vocab_size=2**13) # 有需要可以調整字典大小\n",
    "        if lang == \"zh\":\n",
    "            print(\"Build Chinese Dict\")\n",
    "            subword_encoder = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "          (zh.numpy().decode(\"utf-8\") for _, zh in data), \n",
    "          target_vocab_size=2**13,\n",
    "          max_subword_length=1 # 可以讓每個漢字都會被視為字典裡頭的一個單位\n",
    "            )\n",
    "\n",
    "    # 將字典檔案存下以方便下次 warmstart\n",
    "    subword_encoder.save_to_file(path)\n",
    "    print(f\"字典大小：{subword_encoder.vocab_size}\")\n",
    "    print(f\"前 10 個 subwords：{subword_encoder.subwords[:10]}\")\n",
    "    return subword_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deadly-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "載入已建立的字典： nmt\\en_vocab\n",
      "字典大小：8179\n",
      "前 10 個 subwords：[', ', 'the_', 'to_', 'of_', 'and_', 's_', 'in_', 'a_', 'is_', 'that_']\n"
     ]
    }
   ],
   "source": [
    "en_encoder = build_dict(train_data,en_vocab_file,'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-france",
   "metadata": {},
   "source": [
    "### 所有在中文字典裡的字雖然有 4 萬個，但你只需其中 1 萬個就幾乎可以表達所有意思，其中常用字也才約 2000 個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "korean-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_zh = train_data.take(30000).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "wooden-liberia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有已建立的字典，從頭建立。\n",
      "Build Chinese Dict\n",
      "字典大小：3879\n",
      "前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']\n"
     ]
    }
   ],
   "source": [
    "zh_encoder = build_dict(t_zh,zh_vocab_file,'zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-portable",
   "metadata": {},
   "source": [
    "### 試試看轉成索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "anonymous-implement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3096, 7955, 9, 3023, 3544, 1281, 7969]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_string = 'Taiwan is beautiful.'\n",
    "indices = en_encoder.encode(sample_string)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dense-tactics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taiwan', ' ', 'is ', 'bea', 'uti', 'ful', '.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_back_word(indices,en_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "egyptian-quest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 199, 174, 1, 841, 206]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_string = '欧元区的瓦解'\n",
    "indices = zh_encoder.encode(sample_string)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "taken-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_back_word(indices, encoder):\n",
    "    res = []\n",
    "    for idx in indices: \n",
    "        res.append(encoder.decode([idx]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "lesser-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['欧', '元', '区', '的', '瓦', '解']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_back_word(indices,zh_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-davis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-blind",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-height",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-transformation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-remove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-internet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-laptop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-american",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-coast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-power",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
